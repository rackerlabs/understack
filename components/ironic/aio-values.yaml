---
bootstrap:
  image:
    enabled: false
    openstack:
      enabled: false
  network:
    enabled: false
    openstack:
      enabled: false
  object_store:
    enabled: false
    openstack:
      enabled: false

conductor:
  pxe:
    # at this time we are running our own dnsmasq container and statefulset
    enabled: false

labels:
  conductor:
    node_selector_key: ironic_role
    node_selector_value: conductor

conf:
  ironic:
    DEFAULT:
      # We only want to default to direct, otherwise defaults interfere with hardware
      # types selecting their own defaults. So we purposefully leave the defaults unset
      # but enable everything that our Redfish focused (with iDRAC and iLO support)
      # systems need
      default_deploy_interface: direct
      enabled_bios_interfaces: no-bios,redfish,idrac-redfish,ilo
      enabled_boot_interfaces: http-ipxe,ipxe,redfish-virtual-media,redfish-https,idrac-redfish-virtual-media,ilo-virtual-media,ilo-uefi-https,ilo-ipxe
      enabled_deploy_interfaces: direct,ramdisk
      enabled_firmware_interfaces: redfish,no-firmware
      enabled_hardware_types: redfish,idrac,ilo5,ilo
      enabled_inspect_interfaces: redfish,agent,idrac-redfish,ilo
      enabled_management_interfaces: ipmitool,redfish,idrac-redfish,ilo,ilo5
      enabled_network_interfaces: noop,neutron
      enabled_power_interfaces: redfish,ipmitool,idrac-redfish,ilo
      enabled_raid_interfaces: redfish,idrac-redfish,ilo5,agent
      enabled_vendor_interfaces: redfish,ipmitool,idrac-redfish,ilo
    conductor:
      automated_clean: false
      # (nicholas.kuechler) tuning for idrac hardware type
      # https://docs.openstack.org/ironic/latest/admin/drivers/idrac.html#nodes-go-into-maintenance-mode
      sync_power_state_interval: 70
    agent:
      # (nicholas.kuechler) tuning for idrac hardware type
      # https://docs.openstack.org/ironic/latest/admin/drivers/idrac.html#timeout-when-powering-off
      post_deploy_get_power_state_retry_interval: 18
    dhcp:
      dhcp_provider: dnsmasq
    oslo_messaging_rabbit:
      rabbit_ha_queues: true
    pxe:
      images_path: /var/lib/understack/master_iso_images
      instance_master_path: /var/lib/understack/master_iso_images
    inspector:
      extra_kernel_params: ipa-collect-lldp=1
      hooks: "$default_hooks,parse-lldp,local-link-connection,physical-network"

endpoints:
  oslo_messaging:
    namespace: null
    statefulset:
      replicas: 3
      name: rabbitmq-server
    hosts:
      default: rabbitmq-nodes

network:
  api:
    ingress:
      public: true
      classes:
        namespace: "nginx"
        cluster: "nginx-openstack"
      annotations:
        nginx.ingress.kubernetes.io/rewrite-target: /
    external_policy_local: false
    node_port:
      enabled: false
  pxe:
    # hack to make things not fail on the default case
    device: lo

  # configure OpenStack Helm to use Undercloud's ingress
  # instead of expecting the ingress controller provided
  # by OpenStack Helm
  use_external_ingress_controller: true

dependencies:
  dynamic:
    common:
      local_image_registry:
        jobs: null
  static:
    api:
      jobs:
        - ironic-db-sync
        - ironic-ks-user
        - ironic-ks-endpoints
      services:
        - endpoint: internal
          service: oslo_db
        - endpoint: internal
          service: oslo_messaging
    conductor:
      jobs:
        - ironic-db-sync
        - ironic-ks-user
        - ironic-ks-endpoints
      services:
        - endpoint: internal
          service: oslo_db
        - endpoint: internal
          service: oslo_messaging
    # (nicholas.kuechler) The upstream helm values have ironic-db-init
    # as a dependency for db_sync, but we have job_db_init false so
    # ironic-db-init never gets created, and this dependency won't pass.
    # unset it, so that ironic-db-init is no longer listed in it.
    # https://opendev.org/openstack/openstack-helm/src/branch/master/ironic/values.yaml#L310-L312
    db_sync:
      jobs:

manifests:
  job_db_init: false
  job_db_drop: false
  job_manage_cleaning_network: false
  job_rabbit_init: false
  secret_db: false
  secret_rabbitmq: false
  secret_registry: false
  service_ingress_api: false

pod:
  mounts:
    ironic_conductor:
      ironic_conductor:
        volumeMounts:
          - name: dnsmasq-ironic
            mountPath: /etc/dnsmasq.d/
          - name: dnsmasq-dhcp
            mountPath: /var/lib/dnsmasq/
          - name: understack-data
            mountPath: /var/lib/understack
        volumes:
          - name: dnsmasq-ironic
            persistentVolumeClaim:
              claimName: dnsmasq-ironic
          - name: dnsmasq-dhcp
            persistentVolumeClaim:
              claimName: dnsmasq-dhcp
          - name: understack-data
            persistentVolumeClaim:
              claimName: understack-data
  lifecycle:
    disruption_budget:
      api:
        min_available: 1

# we don't want to enable OpenStack Helm's
# helm.sh/hooks because they set them as
# post-install,post-upgrade which in ArgoCD
# maps to PostSync. However the deployments
# and statefulsets in OpenStack Helm
# depend on the jobs to complete to become
# healthy. Which they cannot because they are in
# the post step and not in the main step.
# Turning this on results in the keys jobs
# editing the annotation which deletes the item
# and wipes our keys.
helm3_hook: false

annotations:
  job:
    ironic_db_sync:
      argocd.argoproj.io/hook: Sync
      argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
    ironic_ks_service:
      argocd.argoproj.io/hook: Sync
      argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
    ironic_ks_user:
      argocd.argoproj.io/hook: Sync
      argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
    ironic_ks_endpoints:
      argocd.argoproj.io/hook: Sync
      argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
