---
release_group: null

conf:
  horizon:
    local_settings:
      config:
        debug: "False"
        endpoint_type: "publicURL"
        use_ssl: "True"
        csrf_cookie_secure: "True"
        session_cookie_secure: "True"
        session_cookie_httponly: "True"
        allowed_hosts:
          - '*'
    local_settings_d:
      # Set default options when creating a server from the
      # horizon UI for a more friendly and efficient user experience.
      # https://docs.openstack.org/horizon/latest/configuration/settings.html#launch-instance-defaults
      _40_launch_instance_settings: |
        LAUNCH_INSTANCE_DEFAULTS = {
            "config_drive": True,
            "create_volume": False,
            "hide_create_volume": False,
            "disable_image": False,
            "disable_instance_snapshot": False,
            "disable_volume": False,
            "disable_volume_snapshot": False,
            "enable_scheduler_hints": True,
            "enable_metadata": True,
            "enable_net_ports": True,
            "default_availability_zone": "Any",
        }

endpoints:
  dashboard:
    host_fqdn_override:
      public:
        tls:
          secretName: keystone-tls-public
          issuerRef:
            name: understack-cluster-issuer
            kind: ClusterIssuer

network:
  # configure OpenStack Helm to use Undercloud's ingress
  # instead of expecting the ingress controller provided
  # by OpenStack Helm
  use_external_ingress_controller: true
  dashboard:
    ingress:
      annotations:
        nginx.ingress.kubernetes.io/rewrite-target: /
        # set our default issuer
        cert-manager.io/cluster-issuer: understack-cluster-issuer

# (nicholas.kuechler) updating the jobs list to remove the 'horizon-db-init' job.
dependencies:
  dynamic:
    common:
      local_image_registry:
        jobs: null
  static:
    db_sync:
      jobs:

manifests:
  job_db_init: false
  secret_db: false
  service_ingress: false

pod:
  lifecycle:
    disruption_budget:
      horizon:
        # this should be set to no more than (pod.replicas.horizon - 1)
        # usually set on per-deployment basis.
        min_available: 0
  mounts:
    # oslo.config autoloads certain paths in alphabetical order
    # which gives us the opportunity to inject secrets and extra
    # configs here. likely the best paths are:
    # /etc/${project}/${prog}.conf.d/*.conf
    # /etc/${project}/${project}.conf.d/*.conf
    # the first would be best for per service separation but since each
    # service is in its own pod they won't overlap. further more there
    # is an issue with that see https://bugs.launchpad.net/oslo.config/+bug/2098514
    # so we'll use the bottom one
    horizon:
      horizon:
        volumeMounts:
          - mountPath: /etc/horizon/horizon.conf.d/db_conn.conf
            name: horizon-db-conn
            subPath: db_conf.conf
            readOnly: true
        volumes:
          - name: horizon-db-conn
            secret:
              secretName: horizon-db-conn
    horizon_db_sync:
      horizon_db_sync:
        volumeMounts:
          - mountPath: /etc/horizon/horizon.conf.d/db_conn.conf
            name: horizon-db-conn
            subPath: db_conf.conf
            readOnly: true
        volumes:
          - name: horizon-db-conn
            secret:
              secretName: horizon-db-conn

# We don't want to enable OpenStack Helm's
# helm.sh/hooks because they set them as
# post-install,post-upgrade which in ArgoCD
# maps to PostSync. However the deployments
# and statefulsets in OpenStack Helm
# depend on the jobs to complete to become
# healthy. Which they cannot because they are in
# the post step and not in the main step.
# Turning this on results in the keys jobs
# editing the annotation which deletes the item
# and wipes our keys.
helm3_hook: false

annotations:
  job:
    horizon_db_sync:
      argocd.argoproj.io/hook: Sync
      argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
      argocd.argoproj.io/sync-options: Replace=true
